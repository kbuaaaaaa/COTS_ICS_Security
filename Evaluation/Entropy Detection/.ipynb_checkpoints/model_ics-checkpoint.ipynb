{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605300f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from pycaret.anomaly import *\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d46478",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['eth.src', 'eth.dst', 'ip.src', 'ip.dst', 'ip.len', 'ip.id', 'ip.ttl', 'ip.proto', 'tcp.srcport', 'tcp.dstport', 'tcp.seq', 'tcp.ack', 'tcp.flags', 'tcp.window_size', 'tcp.time_delta', 'tcp.time_relative', 'attack']\n",
    "# col = ['eth.src', 'eth.dst', 'ip.src', 'ip.dst', 'ip.proto', 'tcp.srcport', 'tcp.dstport','tcp.time_delta','tcp.flags','attack']\n",
    "# data = pd.read_csv('testsets/raw/ics.csv')\n",
    "# time = data['time'].unique().shape[0]\n",
    "# file_entropy = np.zeros((time,data.shape[1]))\n",
    "# attack_entropy = np.zeros((time,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48176ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(value):\n",
    "    uvalue,counts = np.unique(value, return_counts=True)\n",
    "    if value.shape[0] > 1:\n",
    "        return entropy(counts)\n",
    "    else :\n",
    "        return -1\n",
    "\n",
    "def get_entropy(column,i,df):\n",
    "    temp = df.loc[df['time'] == i]\n",
    "    return calc_entropy(temp[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97895503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbabc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(time):\n",
    "#     result = [get_entropy(col[j],i,data) for j in range(1,len(col))]\n",
    "#     if -1 not in result:\n",
    "#         file_entropy[i,1:] = result\n",
    "\n",
    "# file_entropy = file_entropy[~np.any(file_entropy == -1, axis=1)]\n",
    "# file_entropy = file_entropy[~np.all(file_entropy == 0, axis=1)]\n",
    "# attack_entropy = file_entropy[:,-1]\n",
    "    \n",
    "# to_file = pd.DataFrame(file_entropy)\n",
    "# to_file.columns = col\n",
    "# to_file.to_csv('training_entropy.csv', index=False)\n",
    "# attack_to_file = pd.DataFrame(attack_entropy)\n",
    "# attack_to_file.columns = ['attack']\n",
    "# attack_to_file.to_csv('training_attack.csv', index=False)\n",
    "\n",
    "\n",
    "file_entropy = pd.read_csv('testsets/entropy/training_entropy.csv').drop(['time','ip.flags','tcp.hdr_len'],axis = 1).to_numpy()\n",
    "# file_entropy = pd.read_csv('testsets/entropy/training_entropy.csv')[['eth.src', 'eth.dst', 'ip.src', 'ip.dst', 'ip.proto', 'tcp.srcport', 'tcp.dstport','tcp.flags','tcp.time_delta','attack']].to_numpy()\n",
    "attack_entropy = pd.read_csv('testsets/entropy/training_attack.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a297fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "file_entropy = scaler.fit_transform(file_entropy)    \n",
    "attack_time = np.asarray(np.where(attack_entropy > 0))[0]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3a301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_entropy = file_entropy.copy()\n",
    "for i in range(smooth_entropy.shape[1]):\n",
    "    smooth_entropy[:,i] = smooth(smooth_entropy[:,i],1000)\n",
    "\n",
    "smooth_entropy = smooth_entropy[1000:-500,:]\n",
    "for j in range(len(smooth_entropy[:,-1])):\n",
    "    if smooth_entropy[j,-1] > 0:\n",
    "        smooth_entropy[j,-1] = 1\n",
    "        \n",
    "# 1000,1000,-500,4500,0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d005c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_entropy = smooth_entropy[4500:,:]\n",
    "file_entropy = file_entropy[5500:-500,:]\n",
    "smooth_time = np.asarray(np.where(smooth_entropy[:,-1] == 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b31283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(file_entropy.shape[1]-1):\n",
    "#     x = range(file_entropy.shape[0])\n",
    "#     y = file_entropy[:,i]\n",
    "#     points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "#     segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "#     cm = dict(zip(range(0,2,1),list(\"br\")))\n",
    "#     colors = list( map( cm.get , np.isin(x,attack_time) ))\n",
    "\n",
    "#     lc = LineCollection(segments, colors=colors, linewidths= 1)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.add_collection(lc)\n",
    "\n",
    "#     ax.autoscale()\n",
    "#     ax.margins(0.1)\n",
    "#     plt.xlabel('Time (second)')\n",
    "#     plt.ylabel('Entropy')\n",
    "#     plt.title(col[i])\n",
    "#     plt.savefig('plot/all/entropy/all_'+col[i]+'_entropy.pdf') \n",
    "#     plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8c91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,len(col)-1):\n",
    "# # for i in range(0,1):\n",
    "#     x = range(smooth_entropy.shape[0])\n",
    "#     y = smooth_entropy[:,i]\n",
    "#     points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "#     segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "#     cm = dict(zip(range(0,2,1),list(\"br\")))\n",
    "#     colors = list( map( cm.get , np.isin(x,smooth_time) ))\n",
    "\n",
    "#     lc = LineCollection(segments, colors=colors, linewidths=1)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.add_collection(lc)\n",
    "#     ax.autoscale()\n",
    "#     ax.margins(0.1)\n",
    "#     plt.xlabel('Time (second)')\n",
    "#     plt.ylabel('Entropy')\n",
    "#     plt.title(col[i])\n",
    "#     plt.savefig('plot/all/smooth/all_'+col[i]+'_smoooth_entropy.pdf') \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbb3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_entropy = pd.DataFrame(smooth_entropy)\n",
    "smooth_entropy.columns = col\n",
    "\n",
    "file_entropy = pd.DataFrame(file_entropy)\n",
    "file_entropy.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68423ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotcol = np.asarray([['eth.src', 'eth.dst', 'ip.src', 'ip.dst']\n",
    "#           ,['ip.len', 'ip.id', 'ip.ttl', 'ip.proto']\n",
    "#           ,['tcp.srcport', 'tcp.dstport', 'tcp.seq', 'tcp.ack']\n",
    "#           ,['tcp.flags', 'tcp.window_size', 'tcp.time_delta', 'tcp.time_relative']])\n",
    "\n",
    "# fig, axs = plt.subplots(4, 4,constrained_layout = True,figsize=(20,10))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(plotcol)):\n",
    "#     for j in range(len(plotcol[i,:])):\n",
    "#         x = range(file_entropy.shape[0])\n",
    "#         y = file_entropy[plotcol[i,j]]\n",
    "#         points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "#         segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "#         cm = dict(zip(range(0,2,1),list(\"br\")))\n",
    "#         colors = list( map( cm.get , np.isin(x,smooth_time) ))\n",
    "\n",
    "#         lc = LineCollection(segments, colors=colors, linewidths=1)\n",
    "#         axs[i, j].plot(x, y)\n",
    "#         axs[i, j].set_title(plotcol[i,j])\n",
    "#         axs[i, j].add_collection(lc)\n",
    "#         axs[i, j].autoscale()\n",
    "#         axs[i, j].margins(0.1)\n",
    "#         axs[i, j].set(xlabel='Time (second)', ylabel='Entropy')\n",
    "        \n",
    "# plt.savefig('plot/all/entropy/all_entropy.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498d4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotcol = np.asarray([['eth.src', 'eth.dst', 'ip.src', 'ip.dst']\n",
    "#           ,['ip.len', 'ip.id', 'ip.ttl', 'ip.proto']\n",
    "#           ,['tcp.srcport', 'tcp.dstport', 'tcp.seq', 'tcp.ack']\n",
    "#           ,['tcp.flags', 'tcp.window_size', 'tcp.time_delta', 'tcp.time_relative']])\n",
    "\n",
    "# fig, axs = plt.subplots(4, 4,constrained_layout = True,figsize=(20,10))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(plotcol)):\n",
    "#     for j in range(len(plotcol[i,:])):\n",
    "#         x = range(smooth_entropy.shape[0])\n",
    "#         y = smooth_entropy[plotcol[i,j]]\n",
    "#         points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "#         segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "#         cm = dict(zip(range(0,2,1),list(\"br\")))\n",
    "#         colors = list( map( cm.get , np.isin(x,smooth_time) ))\n",
    "\n",
    "#         lc = LineCollection(segments, colors=colors, linewidths=1)\n",
    "#         axs[i, j].plot(x, y)\n",
    "#         axs[i, j].set_title(plotcol[i,j])\n",
    "#         axs[i, j].add_collection(lc)\n",
    "#         axs[i, j].autoscale()\n",
    "#         axs[i, j].margins(0.1)\n",
    "#         axs[i, j].set(xlabel='Time (second)', ylabel='Entropy')\n",
    "        \n",
    "# plt.savefig('plot/all/smooth/all_smooth_entropy.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed66246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_08999\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_08999_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_08999_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_08999_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_08999_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_08999_row1_col0\" class=\"data row1 col0\" >Original Data</td>\n",
       "      <td id=\"T_08999_row1_col1\" class=\"data row1 col1\" >(135691, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_08999_row2_col0\" class=\"data row2 col0\" >Missing Values</td>\n",
       "      <td id=\"T_08999_row2_col1\" class=\"data row2 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_08999_row3_col0\" class=\"data row3 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_08999_row3_col1\" class=\"data row3 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_08999_row4_col0\" class=\"data row4 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_08999_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_08999_row5_col0\" class=\"data row5 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_08999_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_08999_row6_col0\" class=\"data row6 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_08999_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_08999_row7_col0\" class=\"data row7 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_08999_row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_08999_row8_col0\" class=\"data row8 col0\" >Transformed Data</td>\n",
       "      <td id=\"T_08999_row8_col1\" class=\"data row8 col1\" >(135691, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_08999_row9_col0\" class=\"data row9 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_08999_row9_col1\" class=\"data row9 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_08999_row10_col0\" class=\"data row10 col0\" >Use GPU</td>\n",
       "      <td id=\"T_08999_row10_col1\" class=\"data row10 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_08999_row11_col0\" class=\"data row11 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_08999_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_08999_row12_col0\" class=\"data row12 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_08999_row12_col1\" class=\"data row12 col1\" >anomaly-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_08999_row13_col0\" class=\"data row13 col0\" >USI</td>\n",
       "      <td id=\"T_08999_row13_col1\" class=\"data row13 col1\" >15e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_08999_row14_col0\" class=\"data row14 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_08999_row14_col1\" class=\"data row14 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_08999_row15_col0\" class=\"data row15 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_08999_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_08999_row16_col0\" class=\"data row16 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_08999_row16_col1\" class=\"data row16 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_08999_row17_col0\" class=\"data row17 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_08999_row17_col1\" class=\"data row17 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_08999_row18_col0\" class=\"data row18 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_08999_row18_col1\" class=\"data row18 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_08999_row19_col0\" class=\"data row19 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_08999_row19_col1\" class=\"data row19 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_08999_row20_col0\" class=\"data row20 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_08999_row20_col1\" class=\"data row20 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_08999_row21_col0\" class=\"data row21 col0\" >Normalize</td>\n",
       "      <td id=\"T_08999_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_08999_row22_col0\" class=\"data row22 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_08999_row22_col1\" class=\"data row22 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_08999_row23_col0\" class=\"data row23 col0\" >Transformation</td>\n",
       "      <td id=\"T_08999_row23_col1\" class=\"data row23 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_08999_row24_col0\" class=\"data row24 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_08999_row24_col1\" class=\"data row24 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_08999_row25_col0\" class=\"data row25 col0\" >PCA</td>\n",
       "      <td id=\"T_08999_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_08999_row26_col0\" class=\"data row26 col0\" >PCA Method</td>\n",
       "      <td id=\"T_08999_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_08999_row27_col0\" class=\"data row27 col0\" >PCA Components</td>\n",
       "      <td id=\"T_08999_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_08999_row28_col0\" class=\"data row28 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_08999_row28_col1\" class=\"data row28 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_08999_row29_col0\" class=\"data row29 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_08999_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_08999_row30_col0\" class=\"data row30 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_08999_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_08999_row31_col0\" class=\"data row31 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_08999_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_08999_row32_col0\" class=\"data row32 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_08999_row32_col1\" class=\"data row32 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_08999_row33_col0\" class=\"data row33 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_08999_row33_col1\" class=\"data row33 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_08999_row34_col0\" class=\"data row34 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_08999_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_08999_row35_col0\" class=\"data row35 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_08999_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_08999_row36_col0\" class=\"data row36 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_08999_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_08999_row37_col0\" class=\"data row37 col0\" >Clustering</td>\n",
       "      <td id=\"T_08999_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_08999_row38_col0\" class=\"data row38 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_08999_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_08999_row39_col0\" class=\"data row39 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_08999_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_08999_row40_col0\" class=\"data row40 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_08999_row40_col1\" class=\"data row40 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_08999_row41_col0\" class=\"data row41 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_08999_row41_col1\" class=\"data row41 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_08999_row42_col0\" class=\"data row42 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_08999_row42_col1\" class=\"data row42 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_08999_row43_col0\" class=\"data row43 col0\" >Group Features</td>\n",
       "      <td id=\"T_08999_row43_col1\" class=\"data row43 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_08999_row44_col0\" class=\"data row44 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_08999_row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_08999_row45_col0\" class=\"data row45 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_08999_row45_col1\" class=\"data row45 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_08999_row46_col0\" class=\"data row46 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_08999_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_08999_row47_col0\" class=\"data row47 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_08999_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_08999_row48_col0\" class=\"data row48 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_08999_row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08999_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_08999_row49_col0\" class=\"data row49 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_08999_row49_col1\" class=\"data row49 col1\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff090709880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[], ml_usecase='regression',\n",
       "                                       numerical_features=[],\n",
       "                                       target='UNSUPERVISED_DUMMY_TARGET',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='most frequent',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None...\n",
       "                 ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                 ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                 ('cluster_all', 'passthrough'),\n",
       "                 ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\n",
       "                 ('fix_perfect', 'passthrough'),\n",
       "                 ('clean_names', Clean_Colum_Names()),\n",
       "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "          verbose=False),\n",
       " <MLUsecase.ANOMALY: 4>,\n",
       " {},\n",
       " KFold(n_splits=10, random_state=None, shuffle=False),\n",
       " 'lightgbm',\n",
       " [],\n",
       " False,\n",
       " -1,\n",
       " {'abod': <pycaret.containers.models.anomaly.ABODAnomalyContainer at 0x7ff090709d90>,\n",
       "  'cluster': <pycaret.containers.models.anomaly.CBLOFAnomalyContainer at 0x7ff0907091f0>,\n",
       "  'cof': <pycaret.containers.models.anomaly.COFAnomalyContainer at 0x7ff090709b80>,\n",
       "  'iforest': <pycaret.containers.models.anomaly.IForestAnomalyContainer at 0x7ff0907a2f40>,\n",
       "  'histogram': <pycaret.containers.models.anomaly.HBOSAnomalyContainer at 0x7ff0907a29d0>,\n",
       "  'knn': <pycaret.containers.models.anomaly.KNNAnomalyContainer at 0x7ff0907a24c0>,\n",
       "  'lof': <pycaret.containers.models.anomaly.LOFAnomalyContainer at 0x7ff091055e20>,\n",
       "  'svm': <pycaret.containers.models.anomaly.OCSVMAnomalyContainer at 0x7ff091055eb0>,\n",
       "  'pca': <pycaret.containers.models.anomaly.PCAAnomalyContainer at 0x7ff091055f40>,\n",
       "  'mcd': <pycaret.containers.models.anomaly.MCDAnomalyContainer at 0x7ff09105f400>,\n",
       "  'sod': <pycaret.containers.models.anomaly.SODAnomalyContainer at 0x7ff09105f730>,\n",
       "  'sos': <pycaret.containers.models.anomaly.SOSAnomalyContainer at 0x7ff09105f7c0>},\n",
       " 5,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " {'USI',\n",
       "  'X',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'dashboard_logger',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_groups_param_full',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param'},\n",
       " {'tsne': 'Anomaly TSnE (3d)', 'umap': 'UMAP Dimensionality'},\n",
       " 'box-cox',\n",
       " False,\n",
       " '15e2',\n",
       " [('Setup Config',\n",
       "                                  Description                 Value\n",
       "   0                               session_id                   123\n",
       "   1                            Original Data          (135691, 16)\n",
       "   2                           Missing Values                 False\n",
       "   3                         Numeric Features                    16\n",
       "   4                     Categorical Features                     0\n",
       "   5                         Ordinal Features                 False\n",
       "   6                High Cardinality Features                 False\n",
       "   7                  High Cardinality Method                  None\n",
       "   8                         Transformed Data          (135691, 16)\n",
       "   9                                 CPU Jobs                    -1\n",
       "   10                                 Use GPU                 False\n",
       "   11                          Log Experiment                 False\n",
       "   12                         Experiment Name  anomaly-default-name\n",
       "   13                                     USI                  15e2\n",
       "   14                         Imputation Type                simple\n",
       "   15          Iterative Imputation Iteration                  None\n",
       "   16                         Numeric Imputer                  mean\n",
       "   17      Iterative Imputation Numeric Model                  None\n",
       "   18                     Categorical Imputer                  mode\n",
       "   19  Iterative Imputation Categorical Model                  None\n",
       "   20           Unknown Categoricals Handling        least_frequent\n",
       "   21                               Normalize                 False\n",
       "   22                        Normalize Method                  None\n",
       "   23                          Transformation                 False\n",
       "   24                   Transformation Method                  None\n",
       "   25                                     PCA                 False\n",
       "   26                              PCA Method                  None\n",
       "   27                          PCA Components                  None\n",
       "   28                     Ignore Low Variance                 False\n",
       "   29                     Combine Rare Levels                 False\n",
       "   30                    Rare Level Threshold                  None\n",
       "   31                         Numeric Binning                 False\n",
       "   32                         Remove Outliers                 False\n",
       "   33                      Outliers Threshold                  None\n",
       "   34                Remove Multicollinearity                 False\n",
       "   35             Multicollinearity Threshold                  None\n",
       "   36             Remove Perfect Collinearity                 False\n",
       "   37                              Clustering                 False\n",
       "   38                    Clustering Iteration                  None\n",
       "   39                     Polynomial Features                 False\n",
       "   40                       Polynomial Degree                  None\n",
       "   41                    Trignometry Features                 False\n",
       "   42                    Polynomial Threshold                  None\n",
       "   43                          Group Features                 False\n",
       "   44                       Feature Selection                 False\n",
       "   45                Feature Selection Method               classic\n",
       "   46            Features Selection Threshold                  None\n",
       "   47                     Feature Interaction                 False\n",
       "   48                           Feature Ratio                 False\n",
       "   49                   Interaction Threshold                  None),\n",
       "  ('Transformed Data',\n",
       "            eth.src   eth.dst    ip.src    ip.dst    ip.len     ip.id    ip.ttl  \\\n",
       "   0       0.501298  0.501220  0.397611  0.490226  0.487954  0.265925  0.157015   \n",
       "   1       0.501313  0.501234  0.397622  0.490240  0.487909  0.266008  0.157019   \n",
       "   2       0.501301  0.501223  0.397613  0.490229  0.487982  0.265977  0.157016   \n",
       "   3       0.501300  0.501221  0.397612  0.490227  0.487983  0.265936  0.157015   \n",
       "   4       0.501297  0.501218  0.397610  0.490225  0.487982  0.265938  0.157014   \n",
       "   ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "   135686  0.499062  0.499076  0.395837  0.488129  0.495735  0.266755  0.156314   \n",
       "   135687  0.499064  0.499079  0.395839  0.488132  0.495807  0.266758  0.156315   \n",
       "   135688  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       "   135689  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       "   135690  0.499064  0.499078  0.395839  0.488131  0.495836  0.266715  0.156315   \n",
       "   \n",
       "           ip.proto  tcp.srcport  tcp.dstport   tcp.seq   tcp.ack  tcp.flags  \\\n",
       "   0       0.590020     0.136994     0.140935  0.357189  0.365021   0.414596   \n",
       "   1       0.590037     0.136998     0.140939  0.357239  0.365072   0.414608   \n",
       "   2       0.590024     0.136995     0.140936  0.357278  0.365112   0.414599   \n",
       "   3       0.590022     0.136994     0.140936  0.357227  0.365060   0.414597   \n",
       "   4       0.590018     0.136994     0.140935  0.357248  0.365082   0.414595   \n",
       "   ...          ...          ...          ...       ...       ...        ...   \n",
       "   135686  0.588502     0.136439     0.140592  0.380988  0.389038   0.412773   \n",
       "   135687  0.588506     0.136439     0.140593  0.381091  0.389142   0.412775   \n",
       "   135688  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       "   135689  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       "   135690  0.588505     0.136404     0.140556  0.381057  0.389122   0.412775   \n",
       "   \n",
       "           tcp.window_size  tcp.time_delta  tcp.time_relative  \n",
       "   0              0.164762        0.461313           0.425144  \n",
       "   1              0.164647        0.461397           0.425221  \n",
       "   2              0.164702        0.461431           0.425253  \n",
       "   3              0.164770        0.461354           0.425182  \n",
       "   4              0.164745        0.461386           0.425212  \n",
       "   ...                 ...             ...                ...  \n",
       "   135686         0.174078        0.482725           0.444924  \n",
       "   135687         0.174156        0.482816           0.445008  \n",
       "   135688         0.174050        0.482805           0.444998  \n",
       "   135689         0.174050        0.482805           0.444998  \n",
       "   135690         0.174089        0.482794           0.444987  \n",
       "   \n",
       "   [135691 rows x 16 columns]),\n",
       "  ('Transformation Pipeline',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=[],\n",
       "                                         display_types=True, features_todrop=[],\n",
       "                                         id_columns=[], ml_usecase='regression',\n",
       "                                         numerical_features=[],\n",
       "                                         target='UNSUPERVISED_DUMMY_TARGET',\n",
       "                                         time_features=[])),\n",
       "                   ('imputer',\n",
       "                    Simple_Imputer(categorical_strategy='most frequent',\n",
       "                                   fill_value_categorical=None,\n",
       "                                   fill_value_numerical=None...\n",
       "                   ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                   ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                   ('cluster_all', 'passthrough'),\n",
       "                   ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\n",
       "                   ('fix_perfect', 'passthrough'),\n",
       "                   ('clean_names', Clean_Colum_Names()),\n",
       "                   ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "            verbose=False))],\n",
       " {'abod': <pycaret.containers.models.anomaly.ABODAnomalyContainer at 0x7ff09105fc40>,\n",
       "  'cluster': <pycaret.containers.models.anomaly.CBLOFAnomalyContainer at 0x7ff091069130>,\n",
       "  'cof': <pycaret.containers.models.anomaly.COFAnomalyContainer at 0x7ff091069820>,\n",
       "  'iforest': <pycaret.containers.models.anomaly.IForestAnomalyContainer at 0x7ff091069880>,\n",
       "  'histogram': <pycaret.containers.models.anomaly.HBOSAnomalyContainer at 0x7ff0910698e0>,\n",
       "  'knn': <pycaret.containers.models.anomaly.KNNAnomalyContainer at 0x7ff091069940>,\n",
       "  'lof': <pycaret.containers.models.anomaly.LOFAnomalyContainer at 0x7ff091069c40>,\n",
       "  'svm': <pycaret.containers.models.anomaly.OCSVMAnomalyContainer at 0x7ff091069ca0>,\n",
       "  'pca': <pycaret.containers.models.anomaly.PCAAnomalyContainer at 0x7ff091069d00>,\n",
       "  'mcd': <pycaret.containers.models.anomaly.MCDAnomalyContainer at 0x7ff091069d90>,\n",
       "  'sod': <pycaret.containers.models.anomaly.SODAnomalyContainer at 0x7ff091069e20>,\n",
       "  'sos': <pycaret.containers.models.anomaly.SOSAnomalyContainer at 0x7ff091069eb0>},\n",
       " False,\n",
       " Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False),\n",
       " False,\n",
       "          eth.src   eth.dst    ip.src    ip.dst    ip.len     ip.id    ip.ttl  \\\n",
       " 0       0.501298  0.501220  0.397611  0.490226  0.487954  0.265925  0.157015   \n",
       " 1       0.501313  0.501234  0.397622  0.490240  0.487909  0.266008  0.157019   \n",
       " 2       0.501301  0.501223  0.397613  0.490229  0.487982  0.265977  0.157016   \n",
       " 3       0.501300  0.501221  0.397612  0.490227  0.487983  0.265936  0.157015   \n",
       " 4       0.501297  0.501218  0.397610  0.490225  0.487982  0.265938  0.157014   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 135686  0.499062  0.499076  0.395837  0.488129  0.495735  0.266755  0.156314   \n",
       " 135687  0.499064  0.499079  0.395839  0.488132  0.495807  0.266758  0.156315   \n",
       " 135688  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       " 135689  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       " 135690  0.499064  0.499078  0.395839  0.488131  0.495836  0.266715  0.156315   \n",
       " \n",
       "         ip.proto  tcp.srcport  tcp.dstport   tcp.seq   tcp.ack  tcp.flags  \\\n",
       " 0       0.590020     0.136994     0.140935  0.357189  0.365021   0.414596   \n",
       " 1       0.590037     0.136998     0.140939  0.357239  0.365072   0.414608   \n",
       " 2       0.590024     0.136995     0.140936  0.357278  0.365112   0.414599   \n",
       " 3       0.590022     0.136994     0.140936  0.357227  0.365060   0.414597   \n",
       " 4       0.590018     0.136994     0.140935  0.357248  0.365082   0.414595   \n",
       " ...          ...          ...          ...       ...       ...        ...   \n",
       " 135686  0.588502     0.136439     0.140592  0.380988  0.389038   0.412773   \n",
       " 135687  0.588506     0.136439     0.140593  0.381091  0.389142   0.412775   \n",
       " 135688  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       " 135689  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       " 135690  0.588505     0.136404     0.140556  0.381057  0.389122   0.412775   \n",
       " \n",
       "         tcp.window_size  tcp.time_delta  tcp.time_relative  \n",
       " 0              0.164762        0.461313           0.425144  \n",
       " 1              0.164647        0.461397           0.425221  \n",
       " 2              0.164702        0.461431           0.425253  \n",
       " 3              0.164770        0.461354           0.425182  \n",
       " 4              0.164745        0.461386           0.425212  \n",
       " ...                 ...             ...                ...  \n",
       " 135686         0.174078        0.482725           0.444924  \n",
       " 135687         0.174156        0.482816           0.445008  \n",
       " 135688         0.174050        0.482805           0.444998  \n",
       " 135689         0.174050        0.482805           0.444998  \n",
       " 135690         0.174089        0.482794           0.444987  \n",
       " \n",
       " [135691 rows x 16 columns],\n",
       " False,\n",
       " -1,\n",
       " False,\n",
       " 10,\n",
       " 'lightgbm',\n",
       " 123,\n",
       "          eth.src   eth.dst    ip.src    ip.dst    ip.len     ip.id    ip.ttl  \\\n",
       " 0       0.501298  0.501220  0.397611  0.490226  0.487954  0.265925  0.157015   \n",
       " 1       0.501313  0.501234  0.397622  0.490240  0.487909  0.266008  0.157019   \n",
       " 2       0.501301  0.501223  0.397613  0.490229  0.487982  0.265977  0.157016   \n",
       " 3       0.501300  0.501221  0.397612  0.490227  0.487983  0.265936  0.157015   \n",
       " 4       0.501297  0.501218  0.397609  0.490225  0.487982  0.265938  0.157014   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 135686  0.499062  0.499076  0.395837  0.488129  0.495735  0.266755  0.156314   \n",
       " 135687  0.499064  0.499079  0.395839  0.488132  0.495807  0.266758  0.156315   \n",
       " 135688  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       " 135689  0.499066  0.499080  0.395840  0.488133  0.495821  0.266737  0.156316   \n",
       " 135690  0.499064  0.499078  0.395839  0.488131  0.495836  0.266715  0.156315   \n",
       " \n",
       "         ip.proto  tcp.srcport  tcp.dstport   tcp.seq   tcp.ack  tcp.flags  \\\n",
       " 0       0.590020     0.136994     0.140935  0.357189  0.365021   0.414596   \n",
       " 1       0.590037     0.136998     0.140939  0.357239  0.365072   0.414608   \n",
       " 2       0.590024     0.136995     0.140936  0.357278  0.365112   0.414599   \n",
       " 3       0.590022     0.136994     0.140936  0.357227  0.365060   0.414597   \n",
       " 4       0.590018     0.136994     0.140935  0.357248  0.365082   0.414595   \n",
       " ...          ...          ...          ...       ...       ...        ...   \n",
       " 135686  0.588502     0.136439     0.140592  0.380988  0.389038   0.412773   \n",
       " 135687  0.588506     0.136439     0.140593  0.381091  0.389142   0.412775   \n",
       " 135688  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       " 135689  0.588507     0.136405     0.140556  0.381059  0.389125   0.412777   \n",
       " 135690  0.588505     0.136404     0.140556  0.381057  0.389122   0.412775   \n",
       " \n",
       "         tcp.window_size  tcp.time_delta  tcp.time_relative  \n",
       " 0              0.164762        0.461313           0.425144  \n",
       " 1              0.164647        0.461397           0.425221  \n",
       " 2              0.164702        0.461431           0.425253  \n",
       " 3              0.164770        0.461354           0.425182  \n",
       " 4              0.164745        0.461386           0.425212  \n",
       " ...                 ...             ...                ...  \n",
       " 135686         0.174078        0.482725           0.444924  \n",
       " 135687         0.174156        0.482816           0.445008  \n",
       " 135688         0.174050        0.482805           0.444998  \n",
       " 135689         0.174050        0.482805           0.444998  \n",
       " 135690         0.174089        0.482794           0.444987  \n",
       " \n",
       " [135691 rows x 16 columns],\n",
       " 'UNSUPERVISED_DUMMY_TARGET',\n",
       " [],\n",
       " True,\n",
       " [<pandas.io.formats.style.Styler at 0x7ff090709880>],\n",
       " 'anomaly-default-name',\n",
       " None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = smooth_entropy.drop(['attack'],axis=1)\n",
    "setup(X,session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c235aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abod</th>\n",
       "      <td>Angle-base Outlier Detection</td>\n",
       "      <td>pyod.models.abod.ABOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>Clustering-Based Local Outlier</td>\n",
       "      <td>pyod.models.cblof.CBLOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cof</th>\n",
       "      <td>Connectivity-Based Local Outlier</td>\n",
       "      <td>pyod.models.cof.COF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iforest</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>pyod.models.iforest.IForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram</th>\n",
       "      <td>Histogram-based Outlier Detection</td>\n",
       "      <td>pyod.models.hbos.HBOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K-Nearest Neighbors Detector</td>\n",
       "      <td>pyod.models.knn.KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lof</th>\n",
       "      <td>Local Outlier Factor</td>\n",
       "      <td>pyod.models.lof.LOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>One-class SVM detector</td>\n",
       "      <td>pyod.models.ocsvm.OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>pyod.models.pca.PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcd</th>\n",
       "      <td>Minimum Covariance Determinant</td>\n",
       "      <td>pyod.models.mcd.MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sod</th>\n",
       "      <td>Subspace Outlier Detection</td>\n",
       "      <td>pyod.models.sod.SOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sos</th>\n",
       "      <td>Stochastic Outlier Selection</td>\n",
       "      <td>pyod.models.sos.SOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name                    Reference\n",
       "ID                                                                       \n",
       "abod            Angle-base Outlier Detection        pyod.models.abod.ABOD\n",
       "cluster       Clustering-Based Local Outlier      pyod.models.cblof.CBLOF\n",
       "cof         Connectivity-Based Local Outlier          pyod.models.cof.COF\n",
       "iforest                     Isolation Forest  pyod.models.iforest.IForest\n",
       "histogram  Histogram-based Outlier Detection        pyod.models.hbos.HBOS\n",
       "knn             K-Nearest Neighbors Detector          pyod.models.knn.KNN\n",
       "lof                     Local Outlier Factor          pyod.models.lof.LOF\n",
       "svm                   One-class SVM detector      pyod.models.ocsvm.OCSVM\n",
       "pca             Principal Component Analysis          pyod.models.pca.PCA\n",
       "mcd           Minimum Covariance Determinant          pyod.models.mcd.MCD\n",
       "sod               Subspace Outlier Detection          pyod.models.sod.SOD\n",
       "sos             Stochastic Outlier Selection          pyod.models.sos.SOS"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c724bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[], ml_usecase='regression',\n",
       "                                       numerical_features=[],\n",
       "                                       target='UNSUPERVISED_DUMMY_TARGET',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='most frequent',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None...\n",
       "                 ('fix_perfect', 'passthrough'),\n",
       "                 ('clean_names', Clean_Colum_Names()),\n",
       "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough'),\n",
       "                 ['trained_model',\n",
       "                  CBLOF(alpha=0.9, beta=5, check_estimator=False, clustering_estimator=None,\n",
       "    contamination=0.05, n_clusters=8, n_jobs=None, random_state=123,\n",
       "    use_weights=False)]],\n",
       "          verbose=False),\n",
       " 'cluster.pkl')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = create_model('cluster', fraction = 0.05)\n",
    "save_model(cluster,'models/cluster')\n",
    "# cluster_result = assign_model(cluster)\n",
    "# anomaly = cluster_result['Anomaly']\n",
    "# anomaly.to_csv('plot/all/result/all_anomaly_value_cluster.csv', index=False)\n",
    "# pd.DataFrame(smooth_entropy['attack']).to_csv('plot/all/result/all_true_value_cluster.csv', index=False)\n",
    "\n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# fp_time = []\n",
    "# fn_time = []\n",
    "# for i in range(smooth_entropy.shape[0]):\n",
    "#     if i not in smooth_time and anomaly[i]==0:\n",
    "#         TN += 1\n",
    "#     elif i in smooth_time and anomaly[i]==1:\n",
    "#         TP += 1\n",
    "#     elif i in smooth_time and anomaly[i]==0:\n",
    "#         FN += 1\n",
    "#         fn_time.append(i)\n",
    "#     elif i not in smooth_time and anomaly[i]==1:\n",
    "#         FP += 1\n",
    "#         fp_time.append(i)\n",
    "\n",
    "# print(\"True positive =\",TP)\n",
    "# print(\"False positive =\",FP)\n",
    "# print(\"True negative =\",TN)\n",
    "# print(\"False negative =\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "553b4c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'anomaly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/36/vv7_r9x95yv2zwnfqjg7qh7m0000gn/T/ipykernel_11811/2843232069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfn_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmooth_time\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0manomaly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mTN\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmooth_time\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0manomaly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anomaly' is not defined"
     ]
    }
   ],
   "source": [
    "iforest = create_model('iforest', fraction = 0.05)\n",
    "save_model(iforest,'models/iforest')\n",
    "# iforest_result = assign_model(iforest)\n",
    "# anomaly = iforest_result['Anomaly']\n",
    "# anomaly.to_csv('plot/all/result/all_anomaly_value_iforest.csv', index=False)\n",
    "# pd.DataFrame(smooth_entropy['attack']).to_csv('plot/all/result/all_true_value_iforest.csv', index=False)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "fp_time = []\n",
    "fn_time = []\n",
    "for i in range(smooth_entropy.shape[0]):\n",
    "    if i not in smooth_time and anomaly[i]==0:\n",
    "        TN += 1\n",
    "    elif i in smooth_time and anomaly[i]==1:\n",
    "        TP += 1\n",
    "    elif i in smooth_time and anomaly[i]==0:\n",
    "        FN += 1\n",
    "        fn_time.append(i)\n",
    "    elif i not in smooth_time and anomaly[i]==1:\n",
    "        FP += 1\n",
    "        fp_time.append(i)\n",
    "\n",
    "print(\"True positive =\",TP)\n",
    "print(\"False positive =\",FP)\n",
    "print(\"True negative =\",TN)\n",
    "print(\"False negative =\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = create_model('histogram', fraction = 0.05)\n",
    "save_model(histogram,'models/histogram')\n",
    "# histogram_result = assign_model(histogram)\n",
    "# anomaly = histogram_result['Anomaly']\n",
    "# anomaly.to_csv('plot/all/result/all_anomaly_value_histogram.csv', index=False)\n",
    "# pd.DataFrame(smooth_entropy['attack']).to_csv('plot/all/result/all_true_value_histogram.csv', index=False)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "fp_time = []\n",
    "fn_time = []\n",
    "for i in range(smooth_entropy.shape[0]):\n",
    "    if i not in smooth_time and anomaly[i]==0:\n",
    "        TN += 1\n",
    "    elif i in smooth_time and anomaly[i]==1:\n",
    "        TP += 1\n",
    "    elif i in smooth_time and anomaly[i]==0:\n",
    "        FN += 1\n",
    "        fn_time.append(i)\n",
    "    elif i not in smooth_time and anomaly[i]==1:\n",
    "        FP += 1\n",
    "        fp_time.append(i)\n",
    "\n",
    "print(\"True positive =\",TP)\n",
    "print(\"False positive =\",FP)\n",
    "print(\"True negative =\",TN)\n",
    "print(\"False negative =\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e082dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = create_model('svm', fraction = 0.05)\n",
    "save_model(svm,'models/svm')\n",
    "# svm_result = assign_model(svm)\n",
    "# anomaly = svm_result['Anomaly']\n",
    "# anomaly.to_csv('plot/all/result/all_anomaly_value_svm.csv', index=False)\n",
    "# pd.DataFrame(smooth_entropy['attack']).to_csv('plot/all/result/all_true_value_svm.csv', index=False)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "fp_time = []\n",
    "fn_time = []\n",
    "for i in range(smooth_entropy.shape[0]):\n",
    "    if i not in smooth_time and anomaly[i]==0:\n",
    "        TN += 1\n",
    "    elif i in smooth_time and anomaly[i]==1:\n",
    "        TP += 1\n",
    "    elif i in smooth_time and anomaly[i]==0:\n",
    "        FN += 1\n",
    "        fn_time.append(i)\n",
    "    elif i not in smooth_time and anomaly[i]==1:\n",
    "        FP += 1\n",
    "        fp_time.append(i)\n",
    "\n",
    "print(\"True positive =\",TP)\n",
    "print(\"False positive =\",FP)\n",
    "print(\"True negative =\",TN)\n",
    "print(\"False negative =\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = create_model('pca', fraction = 0.05)\n",
    "save_model(pca,'models/pca')\n",
    "# pca_result = assign_model(pca)\n",
    "# anomaly = pca_result['Anomaly']\n",
    "# anomaly.to_csv('plot/all/result/all_anomaly_value_pca.csv', index=False)\n",
    "# pd.DataFrame(smooth_entropy['attack']).to_csv('plot/all/result/all_true_value_pca.csv', index=False)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "fp_time = []\n",
    "fn_time = []\n",
    "for i in range(smooth_entropy.shape[0]):\n",
    "    if i not in smooth_time and anomaly[i]==0:\n",
    "        TN += 1\n",
    "    elif i in smooth_time and anomaly[i]==1:\n",
    "        TP += 1\n",
    "    elif i in smooth_time and anomaly[i]==0:\n",
    "        FN += 1\n",
    "        fn_time.append(i)\n",
    "    elif i not in smooth_time and anomaly[i]==1:\n",
    "        FP += 1\n",
    "        fp_time.append(i)\n",
    "\n",
    "print(\"True positive =\",TP)\n",
    "print(\"False positive =\",FP)\n",
    "print(\"True negative =\",TN)\n",
    "print(\"False negative =\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac1485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12fbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc04764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
